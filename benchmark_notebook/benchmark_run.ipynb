{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Imports"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import glob\n",
                "import json\n",
                "import os\n",
                "import random\n",
                "import subprocess\n",
                "import time\n",
                "\n",
                "from itertools import product\n",
                "from typing import List, Tuple, Dict\n",
                "\n",
                "from benchmark_utils import *"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Function to generate output"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_ground_truth_path(input: str) -> str:\n",
                "    \"\"\"\n",
                "    Get the ground truth path for a given input file\n",
                "    :param input: input file path\n",
                "    :return: ground truth file path or None if not found\n",
                "    \"\"\"\n",
                "    gt = input.replace(\"input\", \"ground truth\")\n",
                "    if os.path.exists(gt):\n",
                "        return gt\n",
                "    gt = input.replace(\"input\", \"ground truth\").replace(\".png\", \".csv\")\n",
                "    if os.path.exists(gt):\n",
                "        return gt\n",
                "    return None\n",
                "\n",
                "\n",
                "def pre_run(inputs: List[str], labels: List[str], has_gt: bool = True) -> List[Tuple[str, str]]:\n",
                "    \"\"\"\n",
                "    Pre-run to get the list of files to run with the program to run\n",
                "    :param inputs: list of input files\n",
                "    :param labels: list of labels\n",
                "    :param has_gt: if True, only keep the files which ground truth is big enough\n",
                "    :return: list of (program, input file) to run\n",
                "    \"\"\"\n",
                "    def keep_input(x: str):\n",
                "        if has_gt:\n",
                "            r = get_ground_truth_path(x)\n",
                "            if not r:\n",
                "                return False\n",
                "        return True\n",
                "\n",
                "    inputs_filtered = list(filter(lambda x: keep_input(x), inputs))\n",
                "    print(\"Unselected for no ground truth: \",\n",
                "          len(inputs) - len(inputs_filtered))\n",
                "\n",
                "    to_run = list(product(labels, inputs_filtered))\n",
                "    random.shuffle(to_run)\n",
                "    to_run.append(to_run[0])  # First launch is always slow\n",
                "\n",
                "    return to_run\n",
                "\n",
                "\n",
                "def get_time_json(time_json_info_save_path: str) -> dict:\n",
                "    \"\"\"\n",
                "    Get the time info json\n",
                "    :param time_json_info_save_path: path to the json file\n",
                "    :return: the json\n",
                "    \"\"\"\n",
                "    if os.path.exists(time_json_info_save_path):\n",
                "        with open(time_json_info_save_path, \"r\") as f:\n",
                "            time_info_json = json.load(f)\n",
                "    else:\n",
                "        time_info_json = {}\n",
                "    return time_info_json\n",
                "\n",
                "\n",
                "def get_file_out(file_in: str, method: str) -> str:\n",
                "    \"\"\"\n",
                "    Get the output file path (and create the folder if needed)\n",
                "    :param file_in: input file path\n",
                "    :param method: method name\n",
                "    :return: output file path\n",
                "    \"\"\"\n",
                "    file_out = file_in.replace(\"input\", \"output\")\n",
                "    path_file_out = os.path.dirname(file_out)\n",
                "    if not os.path.exists(path_file_out):\n",
                "        os.mkdir(path_file_out)\n",
                "    path_file_out_method = os.path.join(path_file_out, method)\n",
                "    if not os.path.exists(path_file_out_method):\n",
                "        os.mkdir(path_file_out_method)\n",
                "    input_basename_without_ext = os.path.splitext(\n",
                "        os.path.basename(file_out))[0]\n",
                "    file_out = os.path.join(path_file_out_method, input_basename_without_ext)\n",
                "    return file_out\n",
                "\n",
                "\n",
                "def run(to_run: List[Tuple[str, str]], cmd_builder, time_json_info_save_path: str) -> None:\n",
                "    \"\"\"\n",
                "    Compute the outputs for a list of input files\n",
                "    :param to_run: list of (method, input file) to run\n",
                "    :param cmd_builder: function that build the command line\n",
                "    :param time_json_info_save_path: path to the json file\n",
                "    \"\"\"\n",
                "    time_info_json = get_time_json(time_json_info_save_path)\n",
                "    for program, file_in in to_run:\n",
                "        file_out = get_file_out(file_in, program)\n",
                "        cmd = cmd_builder(program, file_in, file_out)\n",
                "\n",
                "        t0 = time.time()\n",
                "        s = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
                "        t1 = time.time()\n",
                "\n",
                "        if program not in time_info_json:\n",
                "            time_info_json[program] = {}\n",
                "        file_in_no_ext = os.path.splitext(os.path.basename(file_in))[0]\n",
                "        time_info_json[program][file_in_no_ext] = t1 - t0\n",
                "\n",
                "    with open(time_json_info_save_path, \"w\") as f:\n",
                "        json.dump(time_info_json, f, indent=2)\n",
                "\n",
                "\n",
                "def get_inputs(dataset: str, t: str, item) -> List[str]:\n",
                "    \"\"\"\n",
                "    Get the input files for a dataset\n",
                "    :param dataset: trade_directories | music_sheets | maps\n",
                "    :param t: train | test\n",
                "    :param item: -1 for all, or a list of index\n",
                "    :return: list of input files\n",
                "    \"\"\"\n",
                "    glob_path = os.path.join(dataset_folder, dataset, t, \"input/**\")\n",
                "    inputs = list(glob.glob(glob_path))\n",
                "    if type(item) == list:\n",
                "        inputs = [inputs[f] for f in item]\n",
                "    return inputs\n",
                "\n",
                "\n",
                "def compute_outputs(dataset: str, labels: List[str], cmd_builder, item=-1, to_test=-1, ds_type=\"full\") -> None:\n",
                "    \"\"\"\n",
                "    Compute the outputs for a dataset for a list of labels\n",
                "    :param dataset: trade_directories | music_sheets | maps\n",
                "    :param labels: list of labels\n",
                "    :param cmd_builder: function that build the command line\n",
                "    :param item: -1 for all, or a list of index\n",
                "    :param to_test: -1 for all, or a list of index\n",
                "    :param ds_type: train | test | full\n",
                "    \"\"\"\n",
                "    if not ds_type in [\"train\", \"test\", \"full\"]:\n",
                "        raise Exception(\"Bad type : train | test | full\")\n",
                "\n",
                "    if not dataset in [\"trade_directories\", \"music_sheets\", \"maps\"]:\n",
                "        raise Exception(\n",
                "            \"Bad dataset : trade_directories | music_sheets | maps\")\n",
                "\n",
                "    if to_test != -1:\n",
                "        labels = [labels[to_test]]\n",
                "\n",
                "    ds_type = [\"train\", \"test\"] if ds_type == \"full\" else [ds_type]\n",
                "    has_gt = dataset != \"maps\"\n",
                "\n",
                "    for t in ds_type:\n",
                "        inputs = get_inputs(dataset, t, item)\n",
                "\n",
                "        to_run = pre_run(inputs, labels, has_gt)\n",
                "\n",
                "        time_json_info_save = os.path.join(\n",
                "            dataset_folder, dataset, t, \"time.json\")\n",
                "        run_info = run(to_run, cmd_builder, time_json_info_save)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Comparisons"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Pylene predictors"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "predictor_labels_id: Dict[str, int] = {\n",
                "    'Last observation': 3,\n",
                "    'SMA': 4,\n",
                "    'EMA': 5,\n",
                "    'Double exponential': 2,\n",
                "    'Kalman': 0,\n",
                "    'One euro': 1,\n",
                "}"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Annuaries (vector + time)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "predictors_trade_directories_args: List[str] = [\n",
                "    '--blumi=150', '--llumi=150', '--discontinuity_relative=1', '--minLen=300'\n",
                "]\n",
                "\n",
                "\n",
                "def predictors_trade_directories_cmd_builder(p: str, file_input: Path, output_filename: Path) -> List[str]:\n",
                "    return [pylene_bin] + predictors_trade_directories_args + [f\"--input={file_input}\", f\"--vector_output={output_filename}.csv\"] + [f\"--tracker={predictor_labels_id[p]}\"]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "compute_outputs(\n",
                "    \"trade_directories\",\n",
                "    predictor_labels,\n",
                "    predictors_trade_directories_cmd_builder,\n",
                "    ds_type=\"train\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Music Sheet (pixel + time)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "predictor_music_sheets_args: List[str] = [\n",
                "    \"--max_thickness=6\",\n",
                "    \"--traversal_mode=0\",\n",
                "    \"--discontinuity_relative=5\",\n",
                "    \"--discontinuity_absolute=10\",\n",
                "    \"--sigma_thickness_min_adv=3\",\n",
                "    \"--minLen=1000\",\n",
                "\n",
                "    \"--type_out=3\"\n",
                "]\n",
                "\n",
                "\n",
                "def predictor_music_sheets_cmd_builder(p: str, file_input: Path,  file_output: Path) -> List[str]:\n",
                "    return [pylene_bin] + predictor_music_sheets_args + [f\"--input={file_input}\", f\"--pixel_output={file_output}.png\"] + [f\"--tracker={predictor_labels_id[p]}\"]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "compute_outputs(\n",
                "    \"music_sheets\",\n",
                "    predictor_labels,\n",
                "    predictor_music_sheets_cmd_builder,\n",
                "    ds_type=\"full\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Maps (time)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "predictor_map_args: List[str] = [\n",
                "    \"--blumi=180\", \"--llumi=180\", \"--discontinuity_relative=4\", \"--minLen=20\", \"--type_out=3\", \"--max_thickness=6\"\n",
                "]\n",
                "\n",
                "\n",
                "def predictor_map_cmd_builder(p: str, file_input: Path,  file_output: Path) -> List[str]:\n",
                "    return [pylene_bin] + predictor_map_args + [f\"--input={file_input}\", f\"--output={file_output}.png\"] + [f\"--tracker={predictor_labels_id[p]}\"]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "compute_outputs(\n",
                "    \"maps\",\n",
                "    predictor_labels,\n",
                "    predictor_map_cmd_builder,\n",
                "    ds_type=\"full\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Pylene state of the art "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "sta_labels: List[str] = [\n",
                "    \"pylene\",\n",
                "    \"edlines\",\n",
                "    \"ocv_hough\",\n",
                "    \"cannylines\",\n",
                "    \"lsd\",\n",
                "    \"lsd_m\",\n",
                "    \"elsed\",\n",
                "    \"ag3line\"\n",
                "]"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Annuaries (vector + time)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "sta_trade_directories_args: Dict[str, List[str]] = {\n",
                "    \"pylene\":  ['--llumi=150', '--blumi=150', '--discontinuity_relative=1', '--minLen=300', '--tracker=0'],\n",
                "    \"edlines\":  ['--maxDistanceGap=10', '--minLen=300'],\n",
                "    \"ocv_hough\":  ['--maxGap=10', '--minLen=300', \"--binthresh=150\", \"--threshold=60\"],\n",
                "    \"cannylines\":  ['--minLen=300'],\n",
                "    \"lsd\":  ['--scale=0.99', '--sigma_coef=4.5'],\n",
                "    \"lsd_m\":  ['--minLen=300', '--scale=0.99', '--sigma_coef=4.5'],\n",
                "    \"elsed\":  ['--minLen=300', '--scale=0.99', '--sigma_coef=4.5'],\n",
                "    \"ag3line\":  ['--minLen=300', '--maxGap=10'],\n",
                "}\n",
                "\n",
                "\n",
                "def sta_trade_directories_cmd_builder(program: str, file_input: Path,  file_output: Path) -> List[str]:\n",
                "    return [BIN_FOLDER + \"/lsd_\" + program] + sta_trade_directories_args[program] + [f\"--input={file_input}\", f\"--output={file_output}.csv\"]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "compute_outputs(\n",
                "    \"trade_directories\",\n",
                "    sta_labels,\n",
                "    sta_trade_directories_cmd_builder,\n",
                "    ds_type=\"full\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "lsd_venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.6"
        },
        "orig_nbformat": 4,
        "vscode": {
            "interpreter": {
                "hash": "670fea2cd828d5d425dcff52cbdc464e6699c6e20c86f84523ef8d207eb5f10d"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
