{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "import json\n",
                "import os\n",
                "import subprocess\n",
                "import time\n",
                "\n",
                "from typing import List\n",
                "\n",
                "from benchmark_utils import *\n",
                "\n",
                "import sys\n",
                "root_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\n",
                "# Evaluation Vector\n",
                "sys.path.append(f'{root_dir}/line_detection_evaluation/vector/linelet_modified')\n",
                "from line_detection_evaluation.vector.linelet_modified.evaluate_line_segment import evaluate_line_segment_complete\n",
                "from line_detection_evaluation.vector.linelet_modified.utils import eval_param_struct\n",
                "# Evaluation Pixel\n",
                "from line_detection_evaluation.pixel.icdar_2013.evaluate_staff_line import icdar_2013_evaluate_pixel\n",
                "from line_detection_evaluation.pixel.icdar_2011.evaluate_staff_line import icdar_2011_evaluate_pixel\n",
                "from line_detection_evaluation.pixel.coco.eval_coco import eval_coco_path, eval_coco_path_score"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "def load_lsd_score():\n",
                "    with open('lsd_score.json') as json_file:\n",
                "        data = json.load(json_file)\n",
                "    return data\n",
                "\n",
                "\n",
                "def dump_lsd_score(lsd_score):\n",
                "    with open('lsd_score.json', 'w') as outfile:\n",
                "        json.dump(lsd_score, outfile, indent=4)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "def lem(gt: str, cd: str) -> dict:\n",
                "    try:\n",
                "        evaluation_parameters = eval_param_struct(\n",
                "            30, 3.14 * 5 / 180, .75, False, 300)\n",
                "        (p, r, iou, fsc) = evaluate_line_segment_complete(\n",
                "            gt, cd, evaluation_parameters)\n",
                "    except:\n",
                "        (p, r, iou, fsc) = (None, None, None, None)\n",
                "\n",
                "    return {\n",
                "        \"precision\": p,\n",
                "        \"recall\": r,\n",
                "        \"iou\": iou,\n",
                "        \"fscore\": fsc\n",
                "    }\n",
                "\n",
                "\n",
                "def lems(gt: str, cd: str) -> dict:\n",
                "    try:\n",
                "        evaluation_parameters = eval_param_struct(\n",
                "            30, 3.14 * 5 / 180, .75, True, 300)\n",
                "        (p, r, iou, fsc) = evaluate_line_segment_complete(\n",
                "            gt, cd, evaluation_parameters)\n",
                "    except:\n",
                "        (p, r, iou, fsc) = (None, None, None, None)\n",
                "\n",
                "    return {\n",
                "        \"precision\": p,\n",
                "        \"recall\": r,\n",
                "        \"iou\": iou,\n",
                "        \"fscore\": fsc\n",
                "    }\n",
                "\n",
                "\n",
                "def coco(gt: str, cd: str) -> dict:\n",
                "    try:\n",
                "        (PQ, SQ, RQ) = eval_coco_path_score(gt, cd)\n",
                "    except:\n",
                "        (PQ, SQ, RQ) = (None, None, None)\n",
                "    return {\n",
                "        \"PQ\": PQ,\n",
                "        \"SQ\": SQ,\n",
                "        \"RQ\": RQ\n",
                "    }\n",
                "\n",
                "\n",
                "def icdar2013(gt: str, cd: str) -> dict:\n",
                "    try:\n",
                "        p, r, fscore = icdar_2013_evaluate_pixel(gt, cd)\n",
                "    except:\n",
                "        p, r, fscore = (None, None, None)\n",
                "    return {\n",
                "        \"precision\": p,\n",
                "        \"recall\": r,\n",
                "        \"fscore\": fscore\n",
                "    }\n",
                "\n",
                "\n",
                "evaluations = {\n",
                "    \".csv\": {\n",
                "        \"lem\": lem,\n",
                "        \"lems\": lems,\n",
                "    },\n",
                "    \".png\": {\n",
                "        \"coco\": coco,\n",
                "        \"icdar2013\": icdar2013,\n",
                "    }\n",
                "}\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "def update_partial(method : List[str], experience : str, type : str, build : bool=False):\n",
                "    \"\"\"\n",
                "    Perform the evaluation of the method on the dataset\n",
                "\n",
                "    :param method: The method to evaluate\n",
                "    :param experience: The experience to evaluate\n",
                "    :param type: The type of the experience to evaluate\n",
                "    :param build: If false, the evaluation is performed, otherwise only the json is created\n",
                "    :return: The evaluation of the method on the dataset\n",
                "    \"\"\"\n",
                "    ret = {}\n",
                "\n",
                "    path = os.path.join(dataset_folder, experience, type, 'input')\n",
                "    gt_path = path.replace('input', 'ground truth')\n",
                "    out_path = path.replace('input', 'output')\n",
                "\n",
                "    try:\n",
                "        files = [os.path.splitext(f)[0] for f in os.listdir(path)]\n",
                "        for file in files:\n",
                "            ret[file] = {}\n",
                "            for eval_ext, evalutions_ext in evaluations.items():\n",
                "                for eval_name, eval in evalutions_ext.items():\n",
                "                    if build:\n",
                "                        gt_file = None\n",
                "                        cd_file = None\n",
                "                    else:\n",
                "                        gt_file = os.path.join(gt_path, file + eval_ext)\n",
                "                        cd_file = os.path.join(\n",
                "                            out_path, method, file + eval_ext)\n",
                "                    ret[file][eval_name] = eval(gt_file, cd_file)\n",
                "    except:\n",
                "        print(\"Error in \" + method + \" \" + experience + \" \" + type)\n",
                "        return {}\n",
                "    return ret\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": [
                "def build_json_result() -> dict:\n",
                "    \"\"\"\n",
                "    Build the json result of the evaluation\n",
                "\n",
                "    :return: The json result of the evaluation\n",
                "    \"\"\"\n",
                "    json_out = {}\n",
                "\n",
                "    for method in methods:\n",
                "        json_out[method] = {}\n",
                "        for experience in experiences:\n",
                "            json_out[method][experience] = {}\n",
                "            for type in [\"train\", \"test\"]:\n",
                "                json_out[method][experience][type] = update_partial(\n",
                "                    method, experience, type, evaluations, True)\n",
                "    return json_out\n",
                "\n",
                "# json_out = build_json_result()\n",
                "\n",
                "# with open(json_out_filename, 'w') as f:\n",
                "#     json.dump(json_out, f, indent=2)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": [
                "def update_experience_time(experience : str, methods : List[str], types:List[str]=[\"train\", \"test\"]) -> None:\n",
                "    \"\"\"\n",
                "    Update the time information in the json file\n",
                "\n",
                "    :param experience: The experience to update\n",
                "    :param methods: The methods to update\n",
                "    :param type: The type of the experience to update\n",
                "    :return: None\n",
                "    \"\"\"\n",
                "    ret = load_lsd_score()\n",
                "\n",
                "    for type in types:\n",
                "        time_json = os.path.join(dataset_folder, experience, type, 'time.json')\n",
                "        if not os.path.exists(time_json):\n",
                "            print(f\"Time file not found : {time_json}\")\n",
                "            continue\n",
                "        \n",
                "        with open(time_json) as json_file:\n",
                "            time_data = json.load(json_file)\n",
                "\n",
                "        for method in methods:\n",
                "            if not method in time_data:\n",
                "                continue\n",
                "\n",
                "            for file in ret[method][experience][type]:\n",
                "                ret[method][experience][type][file][\"time\"] = {}\n",
                "                try :\n",
                "                    ret[method][experience][type][file][\"time\"][\"sec\"] = time_data[method][file]\n",
                "                except:\n",
                "                    ret[method][experience][type][file][\"time\"][\"sec\"] = None\n",
                "\n",
                "    dump_lsd_score(ret)\n",
                "\n",
                "def update_experience_evaluation(experience:str, methods:List[str], types:List[str]=['train', 'test']) -> None:\n",
                "    \"\"\"\n",
                "    Update the evaluation of the methods on the dataset\n",
                "\n",
                "    :param experience: The experience to update\n",
                "    :param methods: The methods to update\n",
                "    :param types: The types of the experience to update\n",
                "    :return: None\n",
                "    \"\"\"\n",
                "    ret = load_lsd_score()\n",
                "    t0 = time.time()\n",
                "    for method in methods:\n",
                "        print(method, time.time() - t0)\n",
                "        for type in types:\n",
                "            ret[method][experience][type] = update_partial(\n",
                "                method, experience, type)\n",
                "    dump_lsd_score(ret)\n",
                "\n",
                "def update_experience(experience:str, methods:List[str], types:List[str]) -> None:\n",
                "    \"\"\"\n",
                "    Update the evaluation and the time duration of the methods on the dataset in the json file\n",
                "\n",
                "    :param experience: The experience to update\n",
                "    :param methods: The methods to update\n",
                "    :param types: The types of the experience to update\n",
                "    :return: None\n",
                "    \"\"\"\n",
                "    update_experience_time(experience, methods, types)\n",
                "    update_experience_evaluation(experience, methods, types)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Update experiences"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "experiences: maps music_sheets trade_directories \n",
                        "sta_labels: edlines ocv_hough cannylines lsd lsd_m elsed ag3line \n",
                        "predictor_labels: Last observation SMA EMA Double exponential Kalman One euro \n"
                    ]
                }
            ],
            "source": [
                "def disp(list: List[str], name: str) -> None:\n",
                "    print(f\"{name}: \", end=\"\")\n",
                "    for item in list:\n",
                "        print(item, end=\" \")\n",
                "    print()\n",
                "\n",
                "\n",
                "disp(experiences, \"experiences\")\n",
                "disp(sta_labels, \"sta_labels\")\n",
                "disp(predictor_labels, \"predictor_labels\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Last observation 2.86102294921875e-06\n",
                        "SMA 0.3782026767730713\n",
                        "EMA 0.7154903411865234\n",
                        "Double exponential 1.0589468479156494\n",
                        "Kalman 1.5555832386016846\n",
                        "One euro 1.9646663665771484\n"
                    ]
                }
            ],
            "source": [
                "# update_experience('trade_directories', sta_labels, ['train', 'test']) # 1 hours 10 minutes\n",
                "update_experience('trade_directories', predictor_labels, ['train']) # 1 hours 10 minutes\n",
                "# update_experience('music_sheets',predictor_labels, ['train', 'test']) # 8 hours\n",
                "\n",
                "# update_experience_time('maps',predictor_labels, ['train']) # Only qualitative evaluation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "lsd_venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.6"
        },
        "orig_nbformat": 4,
        "vscode": {
            "interpreter": {
                "hash": "670fea2cd828d5d425dcff52cbdc464e6699c6e20c86f84523ef8d207eb5f10d"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
